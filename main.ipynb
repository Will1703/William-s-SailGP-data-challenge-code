{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d0fba298dd4674a",
   "metadata": {},
   "source": [
    "# SailGP Data Analyst Challenge\n",
    "\n",
    "The aim is to test you python abilities. The challenge is to analyze the data provided and answer the questions below. You can use any library you want to help you with the analysis. The data is from the SailGP event in Auckland 2025. The data is in the 'DATA' folder.\n",
    "\n",
    "There are various sources available.\n",
    "\n",
    "The Boat Logs are in the 'Boat_Logs' folder. The data is in csv format and the columns are described in the 'Boat_Logs/Boat_Logs_Columns.csv' file.\n",
    "The 'Course_Marks_2025-01-19.csv' file contains the mark positions and wind reading on the course for the whole day.\n",
    "\n",
    "The Race_XML folder contains the xml files for each race that contains information on where the boundaries of the course are, the theoretical position of the marks and the target racecourse axis.\n",
    "\n",
    "The 2025-01-19_man_summary.csv file contains the metrics from the manoeuvre summary for the day.\n",
    "The 2025-01-19_straight_lines.csv file contains the metrics from the straight line summary for the day.\n",
    "\n",
    "Both are derived from the boat logs.\n",
    "\n",
    "The 2502 m8_APW_HSB2_HSRW.kph.csv file contains the polar data for the boats in that config.\n",
    "\n",
    "## Requierements\n",
    "- Chose at least 3 questions from the list below to answer.\n",
    "- Python 3.8 or higher\n",
    "- Notebook should be able to run without any errors from start to finish.\n",
    "- Specify the libraries (imports) used in the notebook.\n",
    "- Any comments to make the notebook self-explanatory and easy to follow would be appreciated.\n",
    "- If you can't get to the end of a question, we would appreciate the code you have written so far and explain what you were trying to do.\n",
    "\n",
    "## Further information:\n",
    "- We usually use bokeh for visualizations. So any showcase of bokeh would be appreciated.\n",
    "-\n",
    "\n",
    "## Submitting the results.\n",
    "It would be great if you could provide a jupyter notebook with the code and the results of the analysis. You can submit the results by sharing a link to a git repository.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c766dfd4d17a82",
   "metadata": {},
   "source": [
    "### Imports and re-used functions\n",
    "Free section to initialize the notebook with the necessary imports and functions that will be used in the notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c3955f6358cd7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas_bokeh \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d166957248f0f7",
   "metadata": {},
   "source": [
    "## Question 1: Write a Python function that can take a compass direction (ie. TWD or Heading) and calculate an accurate mean value across a downsampled frequency. Eg. If TWD is at 1Hz, give me a 10s average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "75556c527d1bf0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampled Actual Mean Value Compass Data: [57.43575727958426]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# This module is for demonstrating the compass direction conversion without using and importing the dataset. \n",
    "\n",
    "def circular_mean(angles):\n",
    " \n",
    "\n",
    "   # Calculate the circular mean of a list of angles (in degrees).\n",
    "    \n",
    "    angles_rad = np.deg2rad(angles)  \n",
    "    mean_cos = np.mean(np.cos(angles_rad))  \n",
    "    mean_sin = np.mean(np.sin(angles_rad)) \n",
    "    mean_rad = np.arctan2(mean_sin, mean_cos) \n",
    "    mean_degree = np.rad2deg(mean_rad)  \n",
    "    return mean_degree % 360  \n",
    "\n",
    "def downsample_compass_data(data, original_frequency, target_frequency):\n",
    "    \n",
    "      #  Downsampling compass data and calculate the circular mean value for each interval.\n",
    "      #  data: compass directions in degrees.\n",
    "      #  original_frequency: Original sampling frequency in Hz.\n",
    "      #  target_frequency: Targeted sampling frequency in Hz.\n",
    "      # Returns: downsampled_data: downsampled mean compass directions.\n",
    "    \n",
    "    interval = int(original_frequency // target_frequency)  # Number of samples per downsampled interval\n",
    "    downsampled_data = []\n",
    "    \n",
    "    for i in range(0, len(data), interval):\n",
    "        chunk = data[i:i + interval]\n",
    "        if len(chunk) > 0:\n",
    "            mean_direction = circular_mean(chunk)\n",
    "            downsampled_data.append(mean_direction)\n",
    "    \n",
    "    return downsampled_data\n",
    "    \n",
    "    if original_frequency <= target_frequency:\n",
    "        raise ValueError(\"Target frequency should be lower than the original frequency.\")\n",
    "################################################################################################################################\n",
    "\n",
    "#  If TWD is at 1Hz, give me a 10s average\n",
    "if __name__ == \"__main__\":\n",
    "    # Simulated 1Hz compass data (e.g., TWD or Heading)\n",
    "     original_frequency = 1  # 1Hz\n",
    "    \n",
    "    #  compass directions examples using data_AUS csv file column K TWD_SGP_deg first 10 cells\n",
    "     data = [66.96,53.63,54.16,54.68,55.73,56.69,57.57,58.39,59.15]  \n",
    "   \n",
    "    # Downsample to 0.1Hz 10s average\n",
    "     target_frequency = 0.1\n",
    "    \n",
    "     downsampled_data = downsample_compass_data(data, original_frequency, target_frequency) # output downsampled data\n",
    "    \n",
    "     print(\"Downsampled Actual Mean Value Compass Data:\", downsampled_data)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa948eea67b6d187",
   "metadata": {},
   "source": [
    "## Question 2: Given a course XML and a timeseries of boat Lat/Lon values, calculate a VMC column for the same timeseries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "215a1b096ddf991a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 DATETIME  LATITUDE_GPS_unk  LONGITUDE_GPS_unk        VMC\n",
      "0     2025-01-19 02:56:08        -36.836543         174.767222  32.729371\n",
      "1     2025-01-19 03:06:00        -36.833989         174.761755  13.501404\n",
      "2     2025-01-19 03:06:01        -36.834000         174.761797  14.547035\n",
      "3     2025-01-19 03:06:02        -36.834013         174.761841  15.994771\n",
      "4     2025-01-19 03:06:03        -36.834029         174.761889  16.188467\n",
      "...                   ...               ...                ...        ...\n",
      "2336  2025-01-19 04:22:41        -36.835905         174.758753  38.101930\n",
      "2337  2025-01-19 04:22:42        -36.835920         174.758874  35.032979\n",
      "2338  2025-01-19 04:22:43        -36.835928         174.758987  32.127457\n",
      "2339  2025-01-19 04:22:44        -36.835931         174.759088  28.749217\n",
      "2340  2025-01-19 04:22:45        -36.835929         174.759177  25.226032\n",
      "\n",
      "[2341 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "def calculate_vmc(lat1, lon1, lat2, lon2, speed, cog):\n",
    "   \n",
    "    #Calculate Velocity Made Good (VMC) towards a target point.\n",
    "    \n",
    "    # lat1: Current latitude\n",
    "    # lon1: Current longitude\n",
    "    # lat2: Target latitude\n",
    "    # lon2: Target longitude\n",
    "    # speed: Boat speed in km/h\n",
    "    # cog: Course over ground in degrees\n",
    "    # return: VMC in km/h\n",
    "    \n",
    "    current_point = (lat1, lon1)\n",
    "    target_point = (lat2, lon2)\n",
    "   # bearing_to_target = geodesic(current_point, target_point).initial_bearing\n",
    "    #angle_diff = abs(cog - bearing_to_target)\n",
    "    #vmc = speed * abs(cos(radians(angle_diff)))\n",
    "   # return vmc\n",
    "    from geopy.distance import geodesic, great_circle\n",
    "    from geopy.point import Point\n",
    "##########################################################################################################\n",
    "# Calculates the initial bearing between two GPS coordinates.\n",
    "def initial_bearing(lat1, lon1, lat2, lon2):\n",
    "    \n",
    "    import math\n",
    "    \n",
    "    delta_lon = lon2 - lon1\n",
    "    x = math.sin(math.radians(delta_lon)) * math.cos(math.radians(lat2))\n",
    "    y = (math.cos(math.radians(lat1)) * math.sin(math.radians(lat2)) -\n",
    "         math.sin(math.radians(lat1)) * math.cos(math.radians(lat2)) * math.cos(math.radians(delta_lon)))\n",
    "    bearing = math.atan2(x, y)\n",
    "    return (math.degrees(bearing) + 360) % 360\n",
    "##############################################################################################################\n",
    "    #Calculates the Velocity Made Good (VMC).\n",
    "def calculate_vmc(lat1, lon1, lat2, lon2, speed, cog):\n",
    "    bearing_to_target = initial_bearing(lat1, lon1, lat2, lon2)\n",
    "    angle_diff = abs(cog - bearing_to_target)\n",
    "    vmc = speed * abs(math.cos(math.radians(angle_diff)))\n",
    "    return vmc\n",
    "##############################################################################################################    \n",
    "# Extract course marks from xml file\n",
    "def import_and_process_data(xml_file, csv_file):\n",
    "    # Parse the XML file\n",
    "    with open(xml_file, 'r') as file:\n",
    "        soup = BeautifulSoup(file, 'xml')\n",
    "    marks = []\n",
    "    for mark in soup.find_all('Mark'):\n",
    "        marks.append({\n",
    "            'Name': mark['Name'],\n",
    "            'Lat': float(mark['TargetLat']),\n",
    "            'Lon': float(mark['TargetLng'])\n",
    "        })\n",
    "    \n",
    "    # Read the boat log AUS boat CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Assuming the first mark is the target for VMC calculation\n",
    "    target_mark = marks[0]\n",
    "    target_lat = target_mark['Lat']\n",
    "    target_lon = target_mark['Lon']\n",
    "    \n",
    "    # Calculate VMC for each row in the dataframe\n",
    "    df['VMC'] = df.apply(lambda row: calculate_vmc(\n",
    "        row['LATITUDE_GPS_unk'], row['LONGITUDE_GPS_unk'],\n",
    "        target_lat, target_lon,\n",
    "        row['GPS_SOG_km_h_1'], row['GPS_COG_deg']\n",
    "    ), axis=1)\n",
    "    \n",
    "    return df\n",
    "################################################################################################################\n",
    "# dataset import from first XML file and AUS Boat log data\n",
    "xml_file = 'Data/Race_XMLs/25011905_03-13-55.xml'\n",
    "csv_file =  'Data/Boat_logs/data_AUS.csv'\n",
    "processed_data = import_and_process_data(xml_file, csv_file)\n",
    "print(processed_data[['DATETIME', 'LATITUDE_GPS_unk', 'LONGITUDE_GPS_unk', 'VMC']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eded55c0230916",
   "metadata": {},
   "source": [
    "## Question 3: Verify and comment on the boats calibration. If possible propose a post-calibrated set of wind numbers and a potential calibration table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0fa8ab74285ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9be5cb7d6e14e29",
   "metadata": {},
   "source": [
    "## Question 4: Given a timeseries of Lat/Lon positions and a course XML, in a Python notebook, calculate a Distance to Leader metric for each boat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c225a8b3cf1e382e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c23f6f44eac779",
   "metadata": {},
   "source": [
    "## Question 5: Given a course XML, along with a wind speed and direction and a polar, calculate the minimum number of tacks or gybes for each leg of the course and each gate mark on the leg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f55a57d792cc4849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leg from (-36.834644, 174.769757) to (-36.83533, 174.767562): 0 tacks/gybes required\n",
      "Leg from (-36.83533, 174.767562) to (-36.829713, 174.76527): 9 tacks/gybes required\n",
      "Leg from (-36.829713, 174.76527) to (-36.834715, 174.755873): 0 tacks/gybes required\n",
      "Leg from (-36.834715, 174.755873) to (-36.832976, 174.753778): 7 tacks/gybes required\n",
      "Leg from (-36.832976, 174.753778) to (-36.830518, 174.767965): 6 tacks/gybes required\n",
      "Leg from (-36.830518, 174.767965) to (-36.82907, 174.767251): 8 tacks/gybes required\n",
      "Leg from (-36.82907, 174.767251) to (-36.834715, 174.755873): 0 tacks/gybes required\n",
      "Leg from (-36.834715, 174.755873) to (-36.832976, 174.753778): 7 tacks/gybes required\n",
      "Leg from (-36.832976, 174.753778) to (-36.830518, 174.767965): 6 tacks/gybes required\n",
      "Leg from (-36.830518, 174.767965) to (-36.82907, 174.767251): 8 tacks/gybes required\n",
      "Leg from (-36.82907, 174.767251) to (-36.834715, 174.755873): 0 tacks/gybes required\n",
      "Leg from (-36.834715, 174.755873) to (-36.836315, 174.758068): 0 tacks/gybes required\n",
      "Leg from (-36.836315, 174.758068) to (-36.835426, 174.759055): 7 tacks/gybes required\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import xml.etree.ElementTree as ET\n",
    "from geopy.distance import geodesic\n",
    "import math\n",
    "\n",
    "def parse_course_xml(xml_file):\n",
    "    #Parses the course XML file and extracts waypoints.\n",
    "    with open(xml_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        soup = BeautifulSoup(file, \"xml\")\n",
    "\n",
    "    waypoints = []\n",
    "    for corner in soup.find_all(\"Corner\"):\n",
    "        compound_mark_id = corner[\"CompoundMarkID\"]\n",
    "        mark = soup.find(\"CompoundMark\", {\"CompoundMarkID\": compound_mark_id})\n",
    "        for mark_seq in mark.find_all(\"Mark\"):\n",
    "            lat, lng = float(mark_seq[\"TargetLat\"]), float(mark_seq[\"TargetLng\"])\n",
    "            waypoints.append((lat, lng))\n",
    "\n",
    "    return waypoints\n",
    "\n",
    "def parse_polar_csv(polar_file):\n",
    "   #import the boat polar CSV file into a lookup table.\n",
    "    df = pd.read_csv(polar_file)\n",
    "    df.set_index(df.columns[0], inplace=True)\n",
    "    df.columns = df.columns.astype(float)\n",
    "    return df\n",
    "#Calculates the minimum tacks or gybes needed for a leg\n",
    "def calculate_tacks_or_gybes(start, end, True_wind_direction, polar_df):\n",
    "    start_lat, start_lng = start\n",
    "    end_lat, end_lng = end\n",
    "\n",
    "    # Calculate course bearing (degrees)\n",
    "    bearing = calculate_bearing(start_lat, start_lng, end_lat, end_lng)\n",
    "    \n",
    "    # Determine if upwind or downwind\n",
    "    angle_to_wind = abs(True_wind_direction - bearing) % 360\n",
    "    if angle_to_wind > 180:\n",
    "        angle_to_wind = 360 - angle_to_wind\n",
    "    \n",
    "    # Get VMG angles from polar data, might be need to optimise this as the calculation is a bit simple\n",
    "    best_upwind_angle, best_downwind_angle = get_optimal_angles(polar_df)\n",
    "    \n",
    "    if angle_to_wind < 90:  # Upwind\n",
    "        optimal_angle = best_upwind_angle\n",
    "    elif angle_to_wind > 90:  # Downwind\n",
    "        optimal_angle = best_downwind_angle\n",
    "    else:\n",
    "        return 0  # No tacks/gybes needed if sailing perpendicular to the wind\n",
    "\n",
    "    # Calculate minimum tacks/gybes required\n",
    "    min_turns = calculate_turns(bearing, optimal_angle)\n",
    "    \n",
    "    return min_turns\n",
    "\n",
    "def calculate_bearing(lat1, lon1, lat2, lon2):\n",
    "    #Computes the bearing from (lat1, lon1) to (lat2, lon2).\n",
    "    lat1, lat2 = map(math.radians, [lat1, lat2])\n",
    "    diff_lon = math.radians(lon2 - lon1)\n",
    "\n",
    "    x = math.sin(diff_lon) * math.cos(lat2)\n",
    "    y = math.cos(lat1) * math.sin(lat2) - (math.sin(lat1) * math.cos(lat2) * math.cos(diff_lon))\n",
    "    bearing = math.degrees(math.atan2(x, y))\n",
    "    return (bearing + 360) % 360\n",
    "\n",
    "def get_optimal_angles(polar_df):\n",
    "    #look up the best upwind and downwind VMG angles from the polar table\n",
    "    twa_values = polar_df.index.astype(float)\n",
    "    \n",
    "    upwind_angles = twa_values[twa_values < 90]\n",
    "    downwind_angles = twa_values[twa_values > 90]\n",
    "    \n",
    "    best_upwind_angle = upwind_angles[np.argmax(polar_df.loc[upwind_angles].max(axis=1))]\n",
    "    best_downwind_angle = downwind_angles[np.argmax(polar_df.loc[downwind_angles].max(axis=1))]\n",
    "\n",
    "    return best_upwind_angle, best_downwind_angle\n",
    "\n",
    "def calculate_turns(bearing, optimal_angle):\n",
    "    #Computes the minimum number of tacks or gybes required\n",
    "    angle_diff = 180 - optimal_angle * 2  # Angle covered per tack/gybe\n",
    "    return max(0, math.ceil(abs(bearing - 180) / angle_diff))\n",
    "\n",
    "def analyze_course(xml_file, polar_file, wind_direction):\n",
    "    #Analyzes the course and calculates the required tacks/gybes for each leg.\n",
    "    waypoints = parse_course_xml(xml_file)\n",
    "    polar_df = parse_polar_csv(polar_file)\n",
    "\n",
    "    results = []\n",
    "    for i in range(len(waypoints) - 1):\n",
    "        start, end = waypoints[i], waypoints[i + 1]\n",
    "        turns = calculate_tacks_or_gybes(start, end, True_wind_direction, polar_df)\n",
    "        results.append((start, end, turns))\n",
    "\n",
    "    return results\n",
    "\n",
    "# extract the course xml file and boat polar file\n",
    "xml_file = 'Data/Race_XMLs/25011905_03-13-55.xml'\n",
    "polar_file = 'Data/2502 m8_APW_HSB2_HSRW.kph.csv'\n",
    "True_wind_direction = 40  #pre-set the TWA variables\n",
    "\n",
    "results = analyze_course(xml_file, polar_file, True_wind_direction)\n",
    "for start, end, turns in results:\n",
    "    print(f\"Leg from {start} to {end}: {turns} tacks/gybes required\")\n",
    "\n",
    "    # result is a bit odd with some legs require 0 tacks, need to examine the course xml file to understand the course map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49813bad6749aff0",
   "metadata": {},
   "source": [
    "## Question 6: Calculate a “tacked” set of variables depending on the tack of the boat, so that sailors don’t need to think about what tack they’re on when looking at measurements. And show the results in a visualisation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "939047c7233179e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"f321a2e2-2c70-415a-981b-54b6cc0e95f7\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "'use strict';\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    function drop(id) {\n",
       "      const view = Bokeh.index.get_by_id(id)\n",
       "      if (view != null) {\n",
       "        view.model.document.clear()\n",
       "        Bokeh.index.delete(view)\n",
       "      }\n",
       "    }\n",
       "\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null) {\n",
       "      drop(id)\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim()\n",
       "            drop(id)\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded(error = null) {\n",
       "    const el = document.getElementById(\"f321a2e2-2c70-415a-981b-54b6cc0e95f7\");\n",
       "    if (el != null) {\n",
       "      const html = (() => {\n",
       "        if (typeof root.Bokeh === \"undefined\") {\n",
       "          if (error == null) {\n",
       "            return \"BokehJS is loading ...\";\n",
       "          } else {\n",
       "            return \"BokehJS failed to load.\";\n",
       "          }\n",
       "        } else {\n",
       "          const prefix = `BokehJS ${root.Bokeh.version}`;\n",
       "          if (error == null) {\n",
       "            return `${prefix} successfully loaded.`;\n",
       "          } else {\n",
       "            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n",
       "          }\n",
       "        }\n",
       "      })();\n",
       "      el.innerHTML = html;\n",
       "\n",
       "      if (error != null) {\n",
       "        const wrapper = document.createElement(\"div\");\n",
       "        wrapper.style.overflow = \"auto\";\n",
       "        wrapper.style.height = \"5em\";\n",
       "        wrapper.style.resize = \"vertical\";\n",
       "        const content = document.createElement(\"div\");\n",
       "        content.style.fontFamily = \"monospace\";\n",
       "        content.style.whiteSpace = \"pre-wrap\";\n",
       "        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n",
       "        content.textContent = error.stack ?? error.toString();\n",
       "        wrapper.append(content);\n",
       "        el.append(wrapper);\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(() => display_loaded(error), 100);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.6.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.6.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.6.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.6.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.6.2.min.js\"];\n",
       "  const css_urls = [];\n",
       "\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      try {\n",
       "            for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "\n",
       "      } catch (error) {display_loaded(error);throw error;\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"f321a2e2-2c70-415a-981b-54b6cc0e95f7\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(\"f321a2e2-2c70-415a-981b-54b6cc0e95f7\");\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.6.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.6.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.6.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.6.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.6.2.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {display_loaded(error);throw error;\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"f321a2e2-2c70-415a-981b-54b6cc0e95f7\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"c09beaf8-ef16-45b6-9e3f-6b4993fd54e3\" data-root-id=\"p1952\" style=\"display: contents;\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "  const docs_json = {\"8eb3497a-2b40-4964-81a1-de9c1aff7771\":{\"version\":\"3.6.2\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p1952\",\"attributes\":{\"x_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p1953\"},\"y_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p1954\"},\"x_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1962\"},\"y_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1963\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p1955\",\"attributes\":{\"text\":\"Tacked Variables Visualization\"}},\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1993\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1987\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1988\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1989\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",[0.0,5.070422535211268,10.140845070422536,15.211267605633804,20.281690140845072,25.35211267605634,30.422535211267608,35.49295774647888,40.563380281690144,45.63380281690141,50.70422535211268,55.77464788732395,60.845070422535215,65.91549295774648,70.98591549295776,76.05633802816902,81.12676056338029,86.19718309859155,91.26760563380282,96.3380281690141,101.40845070422536,106.47887323943662,111.5492957746479,116.61971830985917,121.69014084507043,126.7605633802817,131.83098591549296,136.90140845070422,141.97183098591552,147.04225352112678,152.11267605633805,157.1830985915493,162.25352112676057,167.32394366197184,172.3943661971831,177.46478873239437,182.53521126760563,187.60563380281693,192.6760563380282,197.74647887323945,202.81690140845072,207.88732394366198,212.95774647887325,218.0281690140845,223.0985915492958,228.16901408450707,233.23943661971833,238.3098591549296,243.38028169014086,248.45070422535213,253.5211267605634,258.59154929577466,263.6619718309859,268.7323943661972,273.80281690140845,278.8732394366197,283.94366197183103,289.0140845070423,294.08450704225356,299.1549295774648,304.2253521126761,309.29577464788736,314.3661971830986,319.4366197183099,324.50704225352115,329.5774647887324,334.6478873239437,339.71830985915494,344.7887323943662,349.85915492957747,354.92957746478874,360.0]],[\"y\",[10.0,8.59796194838125,7.244102627965477,6.025551399776746,5.103882916513308,4.723617592229977,5.066664965520224,6.054671153134099,7.467385568949001,9.132899888221562,10.95318526010352,12.874458387639638,14.865378003269337,16.905971518995994,18.9822814936269,21.08370633537247,23.201618500270694,25.328613456409595,27.4580853313227,29.583979831191247,31.700647571569068,33.80275652281249,35.885240479201045,37.94327016669694,39.97223897460826,41.967758369663606,43.92565986408086,45.84200150857155,47.71307756436189,49.535430442071146,51.305864275779655,53.02145968456343,54.67958939535867,56.27793448122743,57.81450102097551,59.28763701780483,60.696049431392815,62.03882118264738,63.31542798528331,64.52575484435611,65.67011203948417,66.74925037986185,67.76437547933506,68.717160752783,69.60975878000471,70.44481062075057,71.22545259552932,71.95531997318895,72.63854693088223,73.2797620790441,73.88407877911845,74.45707943237574,75.00479289340126,75.5336641724193,76.05051564836357,76.56249913154222,77.07703830181391,77.60176131344429,78.14442370427186,78.71282217016837,79.31470025232369,79.95764751015145,80.64899428131257,81.39570461808982,82.20427038637096,83.08060977042392,84.02997350144923,85.0568619931147,86.1649562159699,87.35706459165036,88.63508747731731,90.0]]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1994\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1995\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1990\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"#1f77b4\",\"line_width\":2}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1991\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"#1f77b4\",\"line_alpha\":0.1,\"line_width\":2}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1992\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"#1f77b4\",\"line_alpha\":0.2,\"line_width\":2}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p1961\",\"attributes\":{\"tools\":[{\"type\":\"object\",\"name\":\"PanTool\",\"id\":\"p1974\"},{\"type\":\"object\",\"name\":\"WheelZoomTool\",\"id\":\"p1975\",\"attributes\":{\"renderers\":\"auto\"}},{\"type\":\"object\",\"name\":\"BoxZoomTool\",\"id\":\"p1976\",\"attributes\":{\"overlay\":{\"type\":\"object\",\"name\":\"BoxAnnotation\",\"id\":\"p1977\",\"attributes\":{\"syncable\":false,\"line_color\":\"black\",\"line_alpha\":1.0,\"line_width\":2,\"line_dash\":[4,4],\"fill_color\":\"lightgrey\",\"fill_alpha\":0.5,\"level\":\"overlay\",\"visible\":false,\"left\":{\"type\":\"number\",\"value\":\"nan\"},\"right\":{\"type\":\"number\",\"value\":\"nan\"},\"top\":{\"type\":\"number\",\"value\":\"nan\"},\"bottom\":{\"type\":\"number\",\"value\":\"nan\"},\"left_units\":\"canvas\",\"right_units\":\"canvas\",\"top_units\":\"canvas\",\"bottom_units\":\"canvas\",\"handles\":{\"type\":\"object\",\"name\":\"BoxInteractionHandles\",\"id\":\"p1983\",\"attributes\":{\"all\":{\"type\":\"object\",\"name\":\"AreaVisuals\",\"id\":\"p1982\",\"attributes\":{\"fill_color\":\"white\",\"hover_fill_color\":\"lightgray\"}}}}}}}},{\"type\":\"object\",\"name\":\"SaveTool\",\"id\":\"p1984\"},{\"type\":\"object\",\"name\":\"ResetTool\",\"id\":\"p1985\"},{\"type\":\"object\",\"name\":\"HelpTool\",\"id\":\"p1986\"}]}},\"left\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1969\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1970\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1971\"},\"axis_label\":\"Apparent Wind Speed (knots)\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1972\"}}}],\"below\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1964\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1965\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1966\"},\"axis_label\":\"Tacked Wind Angle (degrees)\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1967\"}}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1968\",\"attributes\":{\"axis\":{\"id\":\"p1964\"}}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1973\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p1969\"}}},{\"type\":\"object\",\"name\":\"Legend\",\"id\":\"p1996\",\"attributes\":{\"items\":[{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p1997\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"Apparent Wind Speed\"},\"renderers\":[{\"id\":\"p1993\"}]}}]}}]}}]}};\n",
       "  const render_items = [{\"docid\":\"8eb3497a-2b40-4964-81a1-de9c1aff7771\",\"roots\":{\"p1952\":\"c09beaf8-ef16-45b6-9e3f-6b4993fd54e3\"},\"root_ids\":[\"p1952\"]}];\n",
       "  void root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    let attempts = 0;\n",
       "    const timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "p1952"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "# Function to calculate tacked variables based on the tack of the boat\n",
    "def calculate_tacked_variables(wind_angle, boat_speed, tack):   \n",
    "    \n",
    "   # Parameters:\n",
    "   # wind_angle (float): The angle of the wind relative to the boat (in degrees).\n",
    "   # boat_speed (float): The speed of the boat (in knots).\n",
    "   # tack (str): The tack of the boat, either 'port' or 'starboard'.\n",
    "    \n",
    "   # Returns:\n",
    "\n",
    "    if tack not in ['port', 'starboard']:\n",
    "        raise ValueError(\"Tack must be either 'port' or 'starboard'.\")\n",
    "    \n",
    "    # Adjust wind angle based on tack\n",
    "    if tack == 'port':\n",
    "        tacked_wind_angle = wind_angle\n",
    "    if tack == 'starboard':\n",
    "        tacked_wind_angle = 360 - wind_angle\n",
    "    \n",
    "    # Calculate tacked boat speed (assuming no change in speed, just for demonstration)\n",
    "    tacked_boat_speed = boat_speed\n",
    "    \n",
    "    # Calculate tacked variables (example: apparent wind speed)\n",
    "    apparent_wind_speed = np.sqrt(boat_speed**2 + 10**2 - 2 * boat_speed * 10 * np.cos(np.radians(tacked_wind_angle)))\n",
    "    \n",
    "    return {\n",
    "        'tacked_wind_angle': tacked_wind_angle,\n",
    "        'tacked_boat_speed': tacked_boat_speed,\n",
    "        'apparent_wind_speed': apparent_wind_speed\n",
    "    }\n",
    "\n",
    "# sample data for wind angle from 0 to 360 and bsp from 0 to 100 kph\n",
    "wind_angles = np.linspace(0, 360, 72)\n",
    "boat_speeds = np.linspace(0,100,72)\n",
    "tack = 'port'\n",
    "# tack = 'starboard'\n",
    "\n",
    "# Calculate tacked variables for each wind angle and boat speed\n",
    "tacked_variables = [calculate_tacked_variables(wa, bs, tack) for wa, bs in zip(wind_angles, boat_speeds)]\n",
    "\n",
    "# Extract results for visualization\n",
    "tacked_wind_angles = [tv['tacked_wind_angle'] for tv in tacked_variables]\n",
    "apparent_wind_speeds = [tv['apparent_wind_speed'] for tv in tacked_variables]\n",
    "\n",
    "# Create a Bokeh plot\n",
    "output_notebook()  \n",
    "p = figure(title=\"Tacked Variables Visualization\", x_axis_label='Tacked Wind Angle (degrees)', y_axis_label='Apparent Wind Speed (knots)')\n",
    "p.line(tacked_wind_angles, apparent_wind_speeds, legend_label=\"Apparent Wind Speed\", line_width=2)\n",
    "\n",
    "# Show the plot\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f959e7cb85e711",
   "metadata": {},
   "source": [
    "## Question 7: Given a set of tacks (in CSV), and train a model to explain the key features of these tacks when optimizing for vmg. Show appropriate visualisations to explain your conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9b8435876f454825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Head:\n",
      "  BOAT HULL  WING_CONFIG_unk  MD4_SEL_DB_unk  MD4_SEL_RUD_unk  \\\n",
      "0  AUS  AUS             11.0             3.0              2.0   \n",
      "1  AUS  AUS             11.0             3.0              2.0   \n",
      "2  AUS  AUS             11.0             3.0              2.0   \n",
      "3  AUS  AUS             11.0             3.0              2.0   \n",
      "4  AUS  AUS             11.0             3.0              2.0   \n",
      "\n",
      "                           DATETIME       TIME_LOCAL_unk  race  leg  type  \\\n",
      "0  2025-01-19T02:17:38.600000+00:00  2025-01-19 15:17:57     5    0  gybe   \n",
      "1  2025-01-19T03:32:20.800000+00:00  2025-01-19 16:32:39     6    3  tack   \n",
      "2  2025-01-19T03:33:20.200000+00:00  2025-01-19 16:33:39     6    4  gybe   \n",
      "3  2025-01-19T03:34:17.200000+00:00  2025-01-19 16:34:36     6    4  tack   \n",
      "4  2025-01-19T03:35:17.200000+00:00  2025-01-19 16:35:36     6    5  tack   \n",
      "\n",
      "   ...  loss_vs_targ_vmg  drop_offset  drop_to_wind_axis  htw_bsp  entry_cant  \\\n",
      "0  ...       -205.029352         -0.5                6.6      NaN    4.032800   \n",
      "1  ...         20.583132         -0.5                3.8      NaN   -4.888889   \n",
      "2  ...        -33.845438         -0.5                5.4      NaN   -2.356000   \n",
      "3  ...       -277.490624         -0.5                4.2      NaN   -2.161800   \n",
      "4  ...          6.699322         -0.5                3.4      NaN   -4.848400   \n",
      "\n",
      "   exit_cant  cant_drop_target  cant_stow_target  \\\n",
      "0     2.1764               2.0               0.0   \n",
      "1    -0.1934               0.0               0.0   \n",
      "2     2.0574               2.0               0.0   \n",
      "3    -2.1534               0.0               0.0   \n",
      "4    -2.1250               0.0               0.0   \n",
      "\n",
      "                                           dashboard  entry_tack  \n",
      "0  https://data.sailgp.com/d/f6845b3b-2b56-4a16-a...        port  \n",
      "1  https://data.sailgp.com/d/f6845b3b-2b56-4a16-a...        port  \n",
      "2  https://data.sailgp.com/d/f6845b3b-2b56-4a16-a...        stbd  \n",
      "3  https://data.sailgp.com/d/f6845b3b-2b56-4a16-a...        port  \n",
      "4  https://data.sailgp.com/d/f6845b3b-2b56-4a16-a...        stbd  \n",
      "\n",
      "[5 rows x 109 columns]\n",
      "Missing values found. Handling missing values...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[159], line 125\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# extract data from csv file\u001b[39;00m\n\u001b[0;32m    124\u001b[0m csv_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData/2025-01-19_man_summary.csv\u001b[39m\u001b[38;5;124m'\u001b[39m \n\u001b[1;32m--> 125\u001b[0m analyze_tack_data_with_bokeh(csv_file)\n",
      "Cell \u001b[1;32mIn[159], line 32\u001b[0m, in \u001b[0;36manalyze_tack_data_with_bokeh\u001b[1;34m(csv_file)\u001b[0m\n\u001b[0;32m     29\u001b[0m y \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtheoretical_target_vmg\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Target (VMG)\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# 3 Split the data into training and testing sets\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# 4 Train a Random Forest Regressor model\u001b[39;00m\n\u001b[0;32m     35\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2851\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2848\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2850\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2851\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2852\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m   2853\u001b[0m )\n\u001b[0;32m   2855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2856\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2481\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2478\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2481\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2483\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2484\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2485\u001b[0m     )\n\u001b[0;32m   2487\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.models import ColumnDataSource, HoverTool\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.transform import factor_cmap\n",
    "from bokeh.palettes import Spectral6\n",
    "\n",
    "# Function to import CSV, train a model, and visualize results using Bokeh\n",
    "def analyze_tack_data_with_bokeh(csv_file):\n",
    "    # 1: Import the CSV file\n",
    "    data = pd.read_csv(csv_file)\n",
    "    print(\"Data Head:\")\n",
    "    print(data.head())\n",
    "\n",
    "    # 2: Preprocess the data\n",
    "\n",
    "    if data.isnull().sum().any():\n",
    "        print(\"Missing values found. Handling missing values...\")\n",
    "        data = data.dropna()  # or use data.fillna(...) for more sophisticated handling\n",
    "\n",
    "    # Separate features and target (VMG)\n",
    "    X = data.drop(columns=['theoretical_target_vmg'])  # Features\n",
    "    y = data['theoretical_target_vmg']  # Target (VMG)\n",
    "\n",
    "    # 3 Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 4 Train a Random Forest Regressor model\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 5 Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "    # 6 Feature Importance Analysis\n",
    "    feature_importances = model.feature_importances_\n",
    "    feature_names = X.columns\n",
    "    importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "    importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    print(\"\\nFeature Importances:\")\n",
    "    print(importance_df)\n",
    "\n",
    "    # 7 Permutation Importance for Robustness\n",
    "    result = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=42)\n",
    "    perm_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': result.importances_mean})\n",
    "    perm_importance_df = perm_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    print(\"\\nPermutation Importances:\")\n",
    "    print(perm_importance_df)\n",
    "\n",
    "    # 8 Visualize Feature Importances using Bokeh\n",
    "    output_notebook()  # Render plots in a Jupyter notebook\n",
    "\n",
    "    # Feature Importance Plot\n",
    "    source = ColumnDataSource(importance_df)\n",
    "    p1 = figure(\n",
    "        x_range=importance_df['Feature'],\n",
    "        title=\"Feature Importances for VMG Optimization\",\n",
    "        x_axis_label=\"Feature\",\n",
    "        y_axis_label=\"Importance\",\n",
    "        toolbar_location=None,\n",
    "        tools=\"\"\n",
    "    )\n",
    "    p1.vbar(\n",
    "        x='Feature',\n",
    "        top='Importance',\n",
    "        width=0.9,\n",
    "        source=source,\n",
    "        line_color='white',\n",
    "        fill_color=factor_cmap('Feature', palette=Spectral6, factors=importance_df['Feature'])\n",
    "    )\n",
    "    p1.add_tools(HoverTool(tooltips=[(\"Feature\", \"@Feature\"), (\"Importance\", \"@Importance\")]))\n",
    "    p1.xgrid.grid_line_color = None\n",
    "    p1.y_range.start = 0\n",
    "\n",
    "    # Permutation Importance Plot\n",
    "    source_perm = ColumnDataSource(perm_importance_df)\n",
    "    p2 = figure(\n",
    "        x_range=perm_importance_df['Feature'],\n",
    "        title=\"Permutation Importances for VMG Optimization\",\n",
    "        x_axis_label=\"Feature\",\n",
    "        y_axis_label=\"Importance\",\n",
    "        toolbar_location=None,\n",
    "        tools=\"\"\n",
    "    )\n",
    "    p2.vbar(\n",
    "        x='Feature',\n",
    "        top='Importance',\n",
    "        width=0.9,\n",
    "        source=source_perm,\n",
    "        line_color='white',\n",
    "        fill_color=factor_cmap('Feature', palette=Spectral6, factors=perm_importance_df['Feature'])\n",
    "    )\n",
    "    p2.add_tools(HoverTool(tooltips=[(\"Feature\", \"@Feature\"), (\"Importance\", \"@Importance\")]))\n",
    "    p2.xgrid.grid_line_color = None\n",
    "    p2.y_range.start = 0\n",
    "\n",
    "    # 9 Pairplot for Key Features (Top 3)\n",
    "    top_features = importance_df['Feature'].head(3).tolist()\n",
    "    for feature in top_features:\n",
    "        p = figure(\n",
    "            title=f\"{feature} vs VMG\",\n",
    "            x_axis_label=feature,\n",
    "            y_axis_label=\"VMG\",\n",
    "            tools=\"pan,wheel_zoom,box_zoom,reset,hover\"\n",
    "        )\n",
    "        p.circle(data[feature], data['VMG'], size=8, alpha=0.6)\n",
    "        show(p)\n",
    "\n",
    "    # 10 Show all plots\n",
    "    grid = gridplot([[p1, p2]])\n",
    "    show(grid)\n",
    "\n",
    "# extract data from csv file\n",
    "csv_file = 'Data/2025-01-19_man_summary.csv' \n",
    "analyze_tack_data_with_bokeh(csv_file)\n",
    "\n",
    "#couldn't fix the error in time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997ddc7b58fdbd02",
   "metadata": {},
   "source": [
    "## Question 8: Give insights on the racing on what made a team win or underperform in the race."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc977ed2340f1b78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
